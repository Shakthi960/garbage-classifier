{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4936c108",
   "metadata": {},
   "source": [
    "# üóëÔ∏è Garbage Classification using InceptionResNetV2\n",
    "This notebook trains a deep learning model using **InceptionResNetV2** to classify garbage images into 10 categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a300be",
   "metadata": {},
   "source": [
    "## üìö Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cbd0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import libraries\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c4ac68",
   "metadata": {},
   "source": [
    "## üìÇ Dataset Preparation & Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177bf046",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Data preparation\n",
    "data_dir = '/kaggle/input/garbage-classification-v2/garbage-dataset'\n",
    "classes = ['metal', 'glass', 'biological', 'paper', 'battery', 'trash', 'cardboard', 'shoes', 'clothes', 'plastic']\n",
    "\n",
    "# Create train/test directories (75% train, 25% test)\n",
    "rootdir1 = './Train-TestSplit/'\n",
    "for cls in classes:\n",
    "    os.makedirs(rootdir1 + 'train/' + cls, exist_ok=True)\n",
    "    os.makedirs(rootdir1 + 'test/' + cls, exist_ok=True)\n",
    "    \n",
    "    source = os.path.join(data_dir, cls)\n",
    "    all_files = os.listdir(source)\n",
    "    np.random.shuffle(all_files)\n",
    "    \n",
    "    split_idx = int(len(all_files) * 0.75)\n",
    "    train_files, test_files = all_files[:split_idx], all_files[split_idx:]\n",
    "    \n",
    "    for f in train_files:\n",
    "        shutil.copy(os.path.join(source, f), os.path.join(rootdir1, 'train', cls, f))\n",
    "    for f in test_files:\n",
    "        shutil.copy(os.path.join(source, f), os.path.join(rootdir1, 'test', cls, f))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a0b233",
   "metadata": {},
   "source": [
    "## üîÑ Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242a48a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define constants\n",
    "IMG_SIZE = (299, 299)\n",
    "BATCH_SIZE = 32\n",
    "CLASSES = ['battery', 'biological', 'cardboard', 'clothes', 'glass', \n",
    "           'metal', 'paper', 'plastic', 'shoes', 'trash']\n",
    "\n",
    "# Data generators\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    './Train-TestSplit/train',\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    classes=CLASSES,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    './Train-TestSplit/train',\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    classes=CLASSES,\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "test_generator = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input\n",
    ").flow_from_directory(\n",
    "    './Train-TestSplit/test',\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    classes=CLASSES,\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c98f0e3",
   "metadata": {},
   "source": [
    "## üß† Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654bbcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Model creation\n",
    "base_model = InceptionResNetV2(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(299, 299, 3)\n",
    ")\n",
    "\n",
    "# Freeze base layers\n",
    "base_model.trainable = False\n",
    "\n",
    "# Custom head for 10 classes\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = Model(base_model.input, output)\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ef1311",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Training Setup & Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9602eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training setup\n",
    "nb_train_samples = train_generator.samples\n",
    "nb_validation_samples = validation_generator.samples\n",
    "epochs = 20\n",
    "\n",
    "# Enhanced Callbacks\n",
    "callbacks_list = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='garbage_classifier_10class.keras',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        mode='max',\n",
    "        verbose=1),\n",
    "    \n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=7,\n",
    "        mode='max',\n",
    "        restore_best_weights=True,\n",
    "        verbose=1),\n",
    "    \n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.2,\n",
    "        patience=3,\n",
    "        min_lr=1e-6,\n",
    "        verbose=1)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5f31cb",
   "metadata": {},
   "source": [
    "## üèãÔ∏è Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c20d0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=max(1, nb_train_samples // BATCH_SIZE),\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks_list,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=max(1, nb_validation_samples // BATCH_SIZE),\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Save the final model\n",
    "model.save('final_garbage_classifier.h5')\n",
    "print(\"Training completed and model saved!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd17a0f8",
   "metadata": {},
   "source": [
    "## üìä Training History Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd3c749",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot training history\n",
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "\n",
    "epochs_x = range(1, len(loss_values) + 1)\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.plot(epochs_x, loss_values, 'r', label='Training loss')\n",
    "plt.plot(epochs_x, val_loss_values, 'b', label='Validation loss')\n",
    "plt.title('Training and validation Loss and Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig('EpochVsLoss.jpg', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "acc_values = history_dict['accuracy']\n",
    "val_acc_values = history_dict['val_accuracy']\n",
    "plt.plot(epochs_x, acc_values, 'r', label='Training acc')\n",
    "plt.plot(epochs_x, val_acc_values, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Acc')\n",
    "plt.legend()\n",
    "plt.savefig('EpochVsAcc.jpg', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da08420",
   "metadata": {},
   "source": [
    "## ‚úÖ Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de953d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluation\n",
    "score = model.evaluate(train_generator)\n",
    "print('Train loss:', score[0])\n",
    "print('Train accuracy:', score[1])\n",
    "\n",
    "score = model.evaluate(validation_generator)\n",
    "print('Val loss:', score[0])\n",
    "print('Val accuracy:', score[1])\n",
    "\n",
    "# Save class labels\n",
    "labels = train_generator.class_indices\n",
    "classes1 = {}\n",
    "for key, value in labels.items():\n",
    "    classes1[value] = key.capitalize()\n",
    "\n",
    "with open('classes.pkl', 'wb') as file:\n",
    "    pickle.dump(classes1, file)\n",
    "print('Saved classes to disk!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff54264",
   "metadata": {},
   "source": [
    "## üìå Confusion Matrix & Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef97667",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Confusion matrix and classification report\n",
    "def plot_confusion_matrix(cm, classes, normalize=True, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        cm = np.around(cm, decimals=2)\n",
    "        cm[np.isnan(cm)] = 0.0\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.savefig('Conf.jpg', dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Predictions\n",
    "Y_pred = model.predict(test_generator)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "target_names = CLASSES\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(test_generator.classes, y_pred)\n",
    "plot_confusion_matrix(cm, target_names, normalize=False, title='Confusion Matrix')\n",
    "\n",
    "# Classification Report\n",
    "print('Classification Report')\n",
    "print(classification_report(test_generator.classes, y_pred, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392b1a39",
   "metadata": {},
   "source": [
    "## üñºÔ∏è Single Image Prediction Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4be781",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Single image prediction example\n",
    "img_path = \"/kaggle/working/test/plastic/plastic_1008.jpg\"\n",
    "img = image.load_img(img_path, target_size=(299,299))\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "img_array = image.img_to_array(img)\n",
    "img_batch = np.expand_dims(img_array, axis=0)\n",
    "img_preprocessed = preprocess_input(img_batch)\n",
    "\n",
    "pred = model.predict(img_preprocessed)\n",
    "pred1 = np.argmax(pred, axis=1)\n",
    "\n",
    "with open('./classes.pkl', 'rb') as file:\n",
    "    classes_p = pickle.load(file)\n",
    "\n",
    "print(classes_p[pred1[0]])\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}